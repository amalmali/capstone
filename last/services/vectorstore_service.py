import hashlib
from pathlib import Path
import logging
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from config import VECTORSTORE_DIR, EMBEDDING_MODEL

logging.basicConfig(level=logging.INFO)

class VectorStoreService:
    def __init__(self):
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù€ Embeddings
        self.embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)
        self.loaded_vectorstores = {}

    def _safe_name(self, name: str) -> str:
        return hashlib.md5(name.encode("utf-8")).hexdigest()

    def load_or_create(self, pdf_path: str, name: str):
        safe_name = self._safe_name(name)
        store_path = VECTORSTORE_DIR / safe_name
        
        # 1. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…ÙˆØ¬ÙˆØ¯Ø©ØŒ Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„Ù‡Ø§ ÙƒÙ€ VectorStore
        if store_path.exists() and (store_path / "index.faiss").exists():
            logging.info(f"ğŸ”„ ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹: {name}")
            vs = FAISS.load_local(
                str(store_path), 
                self.embeddings, 
                allow_dangerous_deserialization=True
            )
            return vs 

        # 2. Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø©ØŒ Ù†Ù‚ÙˆÙ… Ø¨Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù Ù…Ù† Ø¬Ø¯ÙŠØ¯
        if not Path(pdf_path).exists():
            raise FileNotFoundError(f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ù ÙÙŠ Ø§Ù„Ù…Ø³Ø§Ø±: {pdf_path}")

        store_path.mkdir(parents=True, exist_ok=True)
        
        try:
            logging.info(f"ğŸ“„ Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù PDF Ø¬Ø¯ÙŠØ¯: {pdf_path}")
            loader = PyPDFLoader(pdf_path)
            docs = loader.load()
            
            # --- Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¬ÙˆÙ‡Ø±ÙŠ Ù‡Ù†Ø§ ---
            # ØªÙ… ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ù‚Ø³Ù…Ø§Øª (Separators) Ù„ØªÙ†Ø§Ø³Ø¨ Ø§Ù„Ù„Ø§Ø¦Ø­Ø© Ø§Ù„Ù…Ø­Ù…Ù„Ø©:
            # - "\nØ§Ù„Ù…Ø§Ø¯Ø©": Ù„Ø¶Ù…Ø§Ù† ÙØµÙ„ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø¨Ø´ÙƒÙ„ Ù†Ø¸ÙŠÙ.
            # - "\nâ€¢": Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø®Ø§Ù„ÙØ§Øª ÙÙŠ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ù…Ù„Ù (ÙƒÙ„ Ù†Ù‚Ø·Ø© Ù‡ÙŠ Ù…Ø®Ø§Ù„ÙØ© ÙˆØºØ±Ø§Ù…ØªÙ‡Ø§).
            # - Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù€ chunk_size Ù„Ø§Ø³ØªÙŠØ¹Ø§Ø¨ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ø·ÙˆÙŠÙ„Ø©.
            splitter = RecursiveCharacterTextSplitter(
                chunk_size=1000, 
                chunk_overlap=150,
                separators=[
                    "\nØ§Ù„Ù…Ø§Ø¯Ø©", 
                    "\nâ€¢", 
                    "\n\n", 
                    ".\n", 
                    "\n", 
                    " "
                ] 
            )
            chunks = splitter.split_documents(docs)

            logging.info(f"ğŸ—ï¸ Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ VectorStore Ù„Ù€ {len(chunks)} Ù‚Ø·Ø¹Ø© Ù†ØµÙŠØ©...")
            
            # Ø¨Ù†Ø§Ø¡ Ø§Ù„ÙÙ‡Ø±Ø³ ÙˆØ­ÙØ¸Ù‡ Ù…Ø­Ù„ÙŠØ§Ù‹
            vs = FAISS.from_documents(chunks, self.embeddings)
            vs.save_local(str(store_path))
            
            logging.info(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ­ÙØ¸ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­: {name}")
            return vs
            
        except Exception as e:
            logging.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ VectorStore: {e}")
            return None

vectorstore_service = VectorStoreService()