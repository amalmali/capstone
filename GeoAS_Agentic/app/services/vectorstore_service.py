# vectorstore_service.py
import hashlib
from pathlib import Path
import logging
from unicodedata import name  # (ØªØ±ÙƒØªÙ‡ ÙƒÙ…Ø§ Ù‡Ùˆ Ù„ØªÙØ§Ø¯ÙŠ Ø­Ø°Ù ØºÙŠØ± Ø¶Ø±ÙˆØ±ÙŠ)

from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS

from config import VECTORSTORE_DIR, EMBEDDING_MODEL, CHUNKS_DIR
import json


logging.basicConfig(level=logging.INFO)


class VectorStoreService:
    def __init__(self):
        # Ù„Ø§ Ù†Ø­Ù…Ù‘Ù„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¹Ù†Ø¯ init
        self.embeddings = None
        self.model_name = EMBEDDING_MODEL
        self.loaded_vectorstores = {}
        logging.info("VectorStoreService initialized (embeddings not loaded yet)")

    # ======================================================
    # ØªØ­Ù…ÙŠÙ„ Embeddings Ø¹Ù†Ø¯ Ø£ÙˆÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù…
    # ======================================================
    def get_embeddings(self):
        if self.embeddings is None:
            try:
                logging.info(f"â³ Loading HuggingFace Embeddings: {self.model_name} ...")
                self.embeddings = HuggingFaceEmbeddings(model_name=self.model_name)
                logging.info("âœ… HuggingFace Embeddings loaded successfully")
            except Exception as e:
                logging.error(f"âŒ Failed to load embeddings: {e}")
                self.embeddings = None
        return self.embeddings

    # ======================================================
    # Ø§Ø³Ù… Ø¢Ù…Ù† Ù„Ù„ØªØ®Ø²ÙŠÙ†
    # ======================================================
    def _safe_name(self, name: str) -> str:
        return hashlib.md5(name.encode("utf-8")).hexdigest()

    # ======================================================
    # Ø­ÙØ¸ Chunks ÙÙŠ Ù…Ù„Ù JSON (Ù…Ø¹ Metadata ÙƒØ§Ù…Ù„Ø©)
    # ======================================================
    def save_chunks_to_file(self, chunks, name: str):
        output_file = CHUNKS_DIR / f"{name}_chunks.json"

        data = []
        for i, c in enumerate(chunks):
            data.append({
                "chunk_id": i + 1,
                "text": (c.page_content or "").strip(),
                # âœ… Ù†Ø­ÙØ¸ ÙƒÙ„ Ø§Ù„Ù€ metadata
                "metadata": c.metadata
            })

        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        logging.info(f"ğŸ§© ØªÙ… Ø­ÙØ¸ {len(data)} Chunks ÙÙŠ: {output_file}")

    # ======================================================
    # ØªØ­Ù…ÙŠÙ„ Ø£Ùˆ Ø¥Ù†Ø´Ø§Ø¡ VectorStore
    # ======================================================
    def load_or_create(self, pdf_path: str, name: str):
        embeddings = self.get_embeddings()
        if embeddings is None:
            logging.error("âŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¥Ù†Ø´Ø§Ø¡ VectorStore Ø¨Ø¯ÙˆÙ† Embeddings")
            return None

        safe_name = self._safe_name(name)
        store_path = VECTORSTORE_DIR / safe_name

        # --------------------------------------------------
        # 1) ØªØ­Ù…ÙŠÙ„ VectorStore Ù…ÙˆØ¬ÙˆØ¯
        # --------------------------------------------------
        if store_path.exists() and (store_path / "index.faiss").exists():
            try:
                logging.info(f"ğŸ”„ ØªØ­Ù…ÙŠÙ„ VectorStore Ù…ÙˆØ¬ÙˆØ¯ Ù…Ø³Ø¨Ù‚Ø§Ù‹: {name}")
                vs = FAISS.load_local(
                    str(store_path),
                    embeddings,
                    allow_dangerous_deserialization=True
                )
                return vs
            except Exception as e:
                logging.error(f"âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ VectorStore Ù…ÙˆØ¬ÙˆØ¯: {e}")
                logging.info("â™»ï¸ Ø³ÙŠØªÙ… Ø¥Ø¹Ø§Ø¯Ø© Ø¥Ù†Ø´Ø§Ø¡ VectorStore...")

        # --------------------------------------------------
        # 2) Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„Ù
        # --------------------------------------------------
        if not Path(pdf_path).exists():
            logging.error(f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ù: {pdf_path}")
            return None

        store_path.mkdir(parents=True, exist_ok=True)

        try:
            logging.info(f"ğŸ“„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù PDF: {pdf_path}")

            loader = PyPDFLoader(pdf_path)
            raw_docs = loader.load()

            # --------------------------------------------------
            # Ø­Ù…Ø§ÙŠØ© Ù…Ù† Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„ÙØ§Ø±ØºØ© Ø£Ùˆ Ø§Ù„ØªØ§Ù„ÙØ©
            # --------------------------------------------------
            valid_docs = []
            for d in raw_docs:
                content = (d.page_content or "").strip()
                if len(content) > 20:
                    valid_docs.append(d)

            if not valid_docs:
                logging.error("âŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Øµ ØµØ§Ù„Ø­ Ø¯Ø§Ø®Ù„ PDF Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ")
                return None

            # --------------------------------------------------
            # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ù€ PDF
            # --------------------------------------------------
            if name == "Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ù„Ø§Ø¦Ø­Ø© Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠØ© Ù„Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ù…Ø­Ù…ÙŠØ©":
                splitter = RecursiveCharacterTextSplitter(
                    chunk_size=700,
                    chunk_overlap=50,
                    separators=[
                        "\n===",
                        "\nâ€” Ø§Ù„ÙØµÙ„",
                        "\n---",
                        "\n",
                        " "
                    ]
                )

            elif name == "protected_areas_rules":
                splitter = RecursiveCharacterTextSplitter(
                    chunk_size=700,
                    chunk_overlap=50,
                    separators=[
                        "\n===",
                        "\nâ€”",
                        "\n",
                        " "
                    ]
                )

            else:
                splitter = RecursiveCharacterTextSplitter(
                    chunk_size=900,
                    chunk_overlap=120,
                    separators=["\n\n", "\n", " ", ""]
                )

            chunks = splitter.split_documents(valid_docs)

            # ==================================================
            # âœ… Ø¥Ø¶Ø§ÙØ© Metadata Ø¨Ø³ÙŠØ·Ø© ÙˆØ¯Ù„Ø§Ù„ÙŠØ© (Ø®ÙŠØ§Ø± A)
            # ==================================================
            for c in chunks:
                text = (c.page_content or "")

                # Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù
                c.metadata["pdf_name"] = name

                # Ø±Ù‚Ù… Ø§Ù„ØµÙØ­Ø©
                c.metadata["page"] = c.metadata.get("page")

                # -------------------------------
                # Ù…Ù„Ù Ù…Ø®Ø§Ù„ÙØ§Øª Ø§Ù„Ù…Ø­Ù…ÙŠØ§Øª
                # -------------------------------
                if name == "protected_areas_rules":

                    if "Ø­Ù…Ø§ÙŠØ© Ø¹Ø§Ù„ÙŠØ©" in text:
                        c.metadata["protection_level"] = "high"
                    elif "Ø­Ù…Ø§ÙŠØ© Ù…ØªÙˆØ³Ø·Ø©" in text:
                        c.metadata["protection_level"] = "medium"
                    elif "Ø­Ù…Ø§ÙŠØ© Ù…Ù†Ø®ÙØ¶Ø©" in text:
                        c.metadata["protection_level"] = "low"
                    else:
                        c.metadata["protection_level"] = "unknown"

                    if "ØµÙŠØ¯" in text:
                        c.metadata["violation_type"] = "hunting"
                    elif "Ø±Ø¹ÙŠ" in text:
                        c.metadata["violation_type"] = "grazing"
                    elif "Ø§Ø­ØªØ·Ø§Ø¨" in text:
                        c.metadata["violation_type"] = "logging"
                    elif "ØªØ®ÙŠÙŠÙ…" in text:
                        c.metadata["violation_type"] = "camping"
                    elif "Ù†Ø§Ø±" in text:
                        c.metadata["violation_type"] = "fire"
                    else:
                        c.metadata["violation_type"] = "general"

                # -------------------------------
                # Ù…Ù„Ù Ø§Ù„Ù„Ø§Ø¦Ø­Ø© Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠØ© (Ø§Ù„Ø¹Ø§Ù…)
                # -------------------------------
                elif name == "Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ù„Ø§Ø¦Ø­Ø© Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠØ© Ù„Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ù…Ø­Ù…ÙŠØ©":

                    c.metadata["doc_type"] = "general_guidelines"

                    if "Ù…Ø­Ù…ÙŠØ©" in text:
                        c.metadata["content_type"] = "reserve_info"
                    elif "Ø§Ù„ØªØ¹Ø¯ÙŠØ§Øª" in text:
                        c.metadata["content_type"] = "violations_info"
                    elif "Ø§Ù„Ø£Ù†ÙˆØ§Ø¹" in text:
                        c.metadata["content_type"] = "biodiversity"
                    else:
                        c.metadata["content_type"] = "general"

            # --------------------------------------------------
            # ØªÙ†Ø¸ÙŠÙ Ø¥Ø¶Ø§ÙÙŠ Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ‚Ø³ÙŠÙ…
            # --------------------------------------------------
            clean_chunks = []
            for c in chunks:
                text = (c.page_content or "").strip()
                if len(text) > 30:
                    clean_chunks.append(c)

            if not clean_chunks:
                logging.error("âŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Chunks ØµØ§Ù„Ø­Ø© Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ‚Ø³ÙŠÙ…")
                return None

            logging.info(f"ğŸ—ï¸ Ø¥Ù†Ø´Ø§Ø¡ VectorStore Ù…Ù† {len(clean_chunks)} Ù‚Ø·Ø¹Ø© Ù†ØµÙŠØ©")

            vs = FAISS.from_documents(clean_chunks, embeddings)
            vs.save_local(str(store_path))

            # ğŸ§© Ø­ÙØ¸ Ø§Ù„Ù€ chunks Ù…Ø¹ metadata
            self.save_chunks_to_file(clean_chunks, name)

            logging.info(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ­ÙØ¸ VectorStore Ø¨Ù†Ø¬Ø§Ø­: {name}")
            return vs

        except Exception as e:
            logging.exception("âŒ ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ VectorStore")
            return None


# ======================================================
# Instance ÙˆØ§Ø­Ø¯ ÙÙ‚Ø· Ù„Ù„Ø®Ø¯Ù…Ø©
# ======================================================
vectorstore_service = VectorStoreService()