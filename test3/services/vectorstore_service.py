import hashlib
from pathlib import Path
import logging
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from config import VECTORSTORE_DIR, EMBEDDING_MODEL

logging.basicConfig(level=logging.INFO)

class VectorStoreService:
    def __init__(self):
        # Ù„Ø§ Ù†Ø­Ù…Ù‘Ù„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¹Ù†Ø¯ init
        self.embeddings = None
        self.model_name = EMBEDDING_MODEL
        self.loaded_vectorstores = {}
        logging.info("VectorStoreService initialized (embeddings not loaded yet)")

    def get_embeddings(self):
        """ØªØ­Ù…ÙŠÙ„ Embeddings Ø¹Ù†Ø¯ Ø£ÙˆÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù…"""
        if self.embeddings is None:
            try:
                logging.info(f"â³ Loading HuggingFace Embeddings: {self.model_name} ...")
                self.embeddings = HuggingFaceEmbeddings(model_name=self.model_name)
                logging.info("âœ… HuggingFace Embeddings loaded successfully")
            except Exception as e:
                logging.error(f"âŒ Failed to load embeddings: {e}")
                self.embeddings = None
        return self.embeddings

    def _safe_name(self, name: str) -> str:
        return hashlib.md5(name.encode("utf-8")).hexdigest()

    def load_or_create(self, pdf_path: str, name: str):
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØªØ­Ù…ÙŠÙ„ Embeddings
        embeddings = self.get_embeddings()
        if embeddings is None:
            logging.error("âŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¥Ù†Ø´Ø§Ø¡ VectorStore Ø¨Ø¯ÙˆÙ† Embeddings")
            return None

        safe_name = self._safe_name(name)
        store_path = VECTORSTORE_DIR / safe_name
        
        # 1. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…ÙˆØ¬ÙˆØ¯Ø©ØŒ Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„Ù‡Ø§
        if store_path.exists() and (store_path / "index.faiss").exists():
            try:
                logging.info(f"ğŸ”„ ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹: {name}")
                vs = FAISS.load_local(
                    str(store_path), 
                    embeddings, 
                    allow_dangerous_deserialization=True
                )
                return vs
            except Exception as e:
                logging.error(f"âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ VectorStore Ù…ÙˆØ¬ÙˆØ¯: {e}")
                # Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„ØªØ­Ù…ÙŠÙ„ØŒ Ù†Ø³ØªÙ…Ø± Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙŠØ¯

        # 2. Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø©ØŒ Ù†Ù‚ÙˆÙ… Ø¨Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù
        if not Path(pdf_path).exists():
            logging.error(f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ù ÙÙŠ Ø§Ù„Ù…Ø³Ø§Ø±: {pdf_path}")
            return None

        store_path.mkdir(parents=True, exist_ok=True)
        
        try:
            logging.info(f"ğŸ“„ Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù PDF Ø¬Ø¯ÙŠØ¯: {pdf_path}")
            loader = PyPDFLoader(pdf_path)
            docs = loader.load()
            
            splitter = RecursiveCharacterTextSplitter(
                chunk_size=1000, 
                chunk_overlap=150,
                separators=[
                    "\nØ§Ù„Ù…Ø§Ø¯Ø©", 
                    "\nâ€¢", 
                    "\n\n", 
                    ".\n", 
                    "\n", 
                    " "
                ] 
            )
            chunks = splitter.split_documents(docs)

            logging.info(f"ğŸ—ï¸ Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ VectorStore Ù„Ù€ {len(chunks)} Ù‚Ø·Ø¹Ø© Ù†ØµÙŠØ©...")

            vs = FAISS.from_documents(chunks, embeddings)
            vs.save_local(str(store_path))
            
            logging.info(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ­ÙØ¸ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­: {name}")
            return vs
            
        except Exception as e:
            logging.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ VectorStore: {e}")
            return None

# Ø¥Ù†Ø´Ø§Ø¡ instance ÙˆÙ„ÙƒÙ† Ø¨Ø¯ÙˆÙ† ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¨Ø¹Ø¯
vectorstore_service = VectorStoreService()
